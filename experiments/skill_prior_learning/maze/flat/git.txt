9e5a25bafe26cf9549b9eebae0ad9b702f26cbe8
diff --git a/README.md b/README.md
index f7a9e48..021f4e7 100644
--- a/README.md
+++ b/README.md
@@ -50,6 +50,7 @@ mkdir ./experiments
 mkdir ./data
 export EXP_DIR=./experiments
 export DATA_DIR=./data
+export PYTHONWARNINGS='ignore:semaphore_tracker:UserWarning'
 ```
 
 Finally, install **our fork** of the [D4RL benchmark](https://github.com/kpertsch/d4rl) repository by following its installation instructions.
@@ -71,6 +72,10 @@ For training a SPIRL agent on the kitchen environment using the pre-trained skil
 python3 spirl/rl/train.py --path=spirl/configs/hrl/kitchen/spirl_cl --seed=0 --prefix=SPIRL_kitchen_seed0
 ```
 
+
+export PYTHONWARNINGS='ignore:semaphore_tracker:UserWarning'
+python3 spirl/rl/train.py --gpu=0 --path=spirl/configs/hrl/maze/spirl_cl --seed=0 --prefix=SPIRL_maze_seed0
+
 In both commands, `kitchen` can be replaced with `maze / block_stacking` to run on the respective environment. Before training models
 on these environments, the corresponding datasets need to be downloaded (the kitchen dataset gets downloaded automatically) 
 -- download links are provided below.
@@ -83,6 +88,8 @@ Additional commands for training baseline models / agents are also provided belo
 python3 spirl/train.py --path=spirl/configs/skill_prior_learning/kitchen/flat --val_data_size=160
 ```
 
+python3 spirl/train.py --gpu 0 --path=spirl/configs/skill_prior_learning/maze/flat --val_data_size=160
+
 - Run **Vanilla SAC**:
 ```
 python3 spirl/rl/train.py --path=spirl/configs/rl/kitchen/SAC --seed=0 --prefix=SAC_kitchen_seed0
diff --git a/spirl/rl/train.py b/spirl/rl/train.py
index 225a09e..bad223f 100644
--- a/spirl/rl/train.py
+++ b/spirl/rl/train.py
@@ -15,8 +15,8 @@ from spirl.rl.utils.rollout_utils import RolloutSaver
 from spirl.rl.components.sampler import Sampler
 from spirl.rl.components.replay_buffer import RolloutStorage
 
-WANDB_PROJECT_NAME = 'your_project_name'
-WANDB_ENTITY_NAME = 'your_entity_name'
+WANDB_PROJECT_NAME = 'sp4'
+WANDB_ENTITY_NAME = 'cehao'
 
 
 class RLTrainer:
diff --git a/spirl/rl/utils/mpi.py b/spirl/rl/utils/mpi.py
index 80ad098..27ce5f5 100644
--- a/spirl/rl/utils/mpi.py
+++ b/spirl/rl/utils/mpi.py
@@ -15,6 +15,8 @@ def update_with_mpi_config(conf):
     mpi_config.rank = rank
     mpi_config.is_chef = rank == 0
     mpi_config.num_workers = MPI.COMM_WORLD.Get_size()
+
+    print("====================== number of workers ", mpi_config.num_workers)
     conf.mpi = mpi_config
 
     # update conf
diff --git a/spirl/train.py b/spirl/train.py
index b48bec3..885c831 100644
--- a/spirl/train.py
+++ b/spirl/train.py
@@ -23,8 +23,8 @@ from spirl.components.trainer_base import BaseTrainer
 from spirl.utils.wandb import WandBLogger
 from spirl.components.params import get_args
 
-WANDB_PROJECT_NAME = 'your_project_name'
-WANDB_ENTITY_NAME = 'your_entity_name'
+WANDB_PROJECT_NAME = 'sp4'
+WANDB_ENTITY_NAME = 'cehao'
 
 
 class ModelTrainer(BaseTrainer):
@@ -212,6 +212,8 @@ class ModelTrainer(BaseTrainer):
     def setup_device(self):
         self.use_cuda = torch.cuda.is_available() and not self.args.debug
         self.device = torch.device('cuda') if self.use_cuda else torch.device('cpu')
+        print('================================== Now device is ', self.device)
+        print('self.args.gpu is ', self.args.gpu)
         if self.args.gpu != -1:
             os.environ["CUDA_VISIBLE_DEVICES"] = str(self.args.gpu)
 
